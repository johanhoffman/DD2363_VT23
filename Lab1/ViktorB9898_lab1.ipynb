{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johanhoffman/DD2363_VT23/blob/ViktorB9898-Lab1/Lab1/ViktorB9898_lab1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RgtXlfYO_i7"
      },
      "source": [
        "# **Lab 1: Matrix Factorization**\n",
        "**Viktor Beck**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9x_J5FVuPzbm"
      },
      "source": [
        "# **Abstract**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UFTSzW7P8kL"
      },
      "source": [
        "This programming assingment features three different functions concerning matrix factorization: a sparse matrix-vector product, QR factorization nad a solver for Ax=b.\n",
        "\n",
        "Each of the functions was implemented based on pseudocode from the book of Professor Hoffman (https://doi-org.focus.lib.kth.se/10.1137/1.9781611976724).\n",
        "\n",
        "Conclusion: testing of the algorithms delivered good results which means they are at least correct but especially function 2 and 3 are not very efficient."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkT8J7uOWpT3"
      },
      "source": [
        "#**About the code**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Pdll1Xc9WP0e",
        "outputId": "d4bb01e1-6322-4d94-d37f-2e577a5440a3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'KTH Royal Institute of Technology, Stockholm, Sweden.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "\"\"\"This program is a lab report in the course\"\"\"\n",
        "\"\"\"DD2363 Methods in Scientific Computing, \"\"\"\n",
        "\"\"\"KTH Royal Institute of Technology, Stockholm, Sweden.\"\"\"\n",
        "\n",
        "# Copyright (C) 2023 Viktor Beck (vbeck@kth.se / viktor.beck98@gmail.com)\n",
        "\n",
        "# This file is part of the course DD2363 Methods in Scientific Computing\n",
        "# KTH Royal Institute of Technology, Stockholm, Sweden"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28xLGz8JX3Hh"
      },
      "source": [
        "# **Set up environment**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2PYNusD08Wa"
      },
      "source": [
        "To have access to the neccessary modules you have to run this cell. If you need additional modules, this is where you add them. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Xw7VlErAX7NS"
      },
      "outputs": [],
      "source": [
        "# Load neccessary modules.\n",
        "from google.colab import files\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import tri\n",
        "from matplotlib import axes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnO3lhAigLev"
      },
      "source": [
        "# **Introduction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5zMzgPlRAF6"
      },
      "source": [
        "This programming assingment features three different functions concerning matrix factorization: a sparse matrix-vector product, QR factorization and a solver for Ax=b. Such methods are fundamental for solving linear algebra problems numerically. The examples of such problems are endless. Starting from machine learning algorithms to fluid simulations.\n",
        "\n",
        "The chosen algorithms produce correct results but are in general not the most efficient ones. Efficiency was not tested here but in general, one can say that dense matrix-vector multiplication brings a lot of computational effort. There are other algorithms that are more suitable for large simulations (except maybe function 1) or any other problem that has to work with large matrices and / or has to run a lot of iterations. A solution to this could be parallelizing some of the steps. E.g. matrix-vector multiplication of large matrices is often ported to the GPU for parallel computation.\n",
        "\n",
        "The input for this Lab report was taken from the book of Professor Hoffman (https://doi-org.focus.lib.kth.se/10.1137/1.9781611976724) which corresponds to the content of the course:\n",
        "\n",
        "[Hyperlink to DD2363 course website.](https://kth.instructure.com/courses/17068)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOQvukXZq5U5"
      },
      "source": [
        "# **Method**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C49r7BC47PQh"
      },
      "source": [
        "### **1. Function: sparse matrix-vector product**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gop-9eQMrZ5g"
      },
      "source": [
        "Here we simply implement the pseudo code from Lecture 1 (Chapter 5.8). The input is given as a matrix in CRS format and a vector. The output is the matrix-vector product of those.\n",
        "\n",
        "The function iterates over the rows of the matrix and multiplies each of the (non-zero) entries with the corresponding entry of the vector and sums them up."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6aes6Sz2rZ5g"
      },
      "outputs": [],
      "source": [
        "def sparse_matvec_product(val, col_idx, row_ptr, x):\n",
        "    b = np.zeros(len(x))\n",
        "    for i in range(len(x)):\n",
        "        for j in range(row_ptr[i]-1,row_ptr[i+1]-1):\n",
        "            b[i] += val[j]*x[col_idx[j]-1]\n",
        "    return b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ah7oYwqrZ5h"
      },
      "source": [
        "### **2. Function: QR factorization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Kjj0J-VrZ5h"
      },
      "source": [
        "Here we use the Gram-Schmidt QR factorization algorithm from Chapter 5.3. The algorithm uses the Gram-Schmidt method to produce the matrices Q and R. In each iteration one of the column vectors of A is taken and iteratively orthogonalized in another loop. After this inner loop the column vector is getting normalized and stored as a column vector of Q. Entries of R are produced as a byproduct along the way."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "W8IBlDHKrZ5h"
      },
      "outputs": [],
      "source": [
        "def QR_factorization(A):\n",
        "    n = A.shape[0]\n",
        "    Q = np.zeros([n,n])\n",
        "    R = np.zeros([n,n])\n",
        "    i = 0\n",
        "    for j in range(n):\n",
        "        v = A[:,j]\n",
        "        for i in range(j):\n",
        "            R[i,j] = np.dot(Q[:,i], v)\n",
        "            v = v - R[i,j]*Q[:,i]\n",
        "        R[j,j] = np.linalg.norm(v)\n",
        "        Q[:,j] = v/R[j,j]\n",
        "    return Q, R"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocrZz1BXrZ5h"
      },
      "source": [
        "### **3. Function: direct solver Ax=b**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BX7nRCigrZ5h"
      },
      "source": [
        "This function is called Richardson iteration solver. It is a rather simple solver for this problem but works nervertheless. The method converges as long as $||I-\\alpha A||<1$. \n",
        "\n",
        "In every iteration the residual is calculated as $r_{k}=Ax_{k}$ and from that x. By this x takes a step in the direction of the residual with each iteration. The function runs as long as the residual is greater than a certain tolerance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "JFgZkaUfrZ5j"
      },
      "outputs": [],
      "source": [
        "def richardson_iteration(A, b, alpha, tol):\n",
        "    n = len(b)\n",
        "    x = np.zeros(n)\n",
        "    r = b\n",
        "    b_norm = np.linalg.norm(b)\n",
        "    while np.linalg.norm(r)/b_norm > tol:\n",
        "        r = np.matmul(A,x)\n",
        "        r = b - r\n",
        "        x = x + alpha * r\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsQLT38gVbn_"
      },
      "source": [
        "# **Results**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oy_RIBAkrZ5j"
      },
      "source": [
        "### **1. Function: sparse matrix-vector product**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDg9PtAFrZ5j",
        "outputId": "b9a17e06-89ad-44bd-dc0e-417c804073da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7. 3. 1. 5. 1. 5.]\n"
          ]
        }
      ],
      "source": [
        "# input\n",
        "# matrix A\n",
        "val =     np.array([3,2,2,2,1,1,3,2,1,2,3])\n",
        "col_idx = np.array([1,2,4,2,3,3,3,4,5,5,6])\n",
        "row_ptr = np.array([1,4,6,7,9,10,12])\n",
        "# vector x\n",
        "n = len(row_ptr)-1\n",
        "x = np.ones(n)\n",
        "\n",
        "# execute function\n",
        "b_sparse = sparse_matvec_product(val, col_idx, row_ptr, x)\n",
        "print(b_sparse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLwlnOzuV-Cd"
      },
      "source": [
        "To test if the algorithm works correctly the corresponding dense matrix-vector multiplication is performed:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djMjrreerZ5k",
        "outputId": "e164d7e1-bdb1-46fa-b533-a77ea6ac4696"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b with sparse matrix multiplication:\t [7. 3. 1. 5. 1. 5.]\n",
            "b with dense matrix multiplication:\t [7. 3. 1. 5. 1. 5.]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "A = np.array([[3,2,0,2,0,0],\n",
        "              [0,2,1,0,0,0],\n",
        "              [0,0,1,0,0,0],\n",
        "              [0,0,3,2,0,0],\n",
        "              [0,0,0,0,1,0],\n",
        "              [0,0,0,0,2,3]])\n",
        "\n",
        "b_dense = np.matmul(A,x, out=None)\n",
        "\n",
        "print(\"b with sparse matrix multiplication:\\t\", b_sparse)\n",
        "print(\"b with dense matrix multiplication:\\t\", b_dense)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EwjPXPVJrZ5k"
      },
      "source": [
        "### **2. Function: QR factorization**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRt7JtoGrZ5k"
      },
      "source": [
        "One can see that matrix R is upper trianguar:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8a3x6yBrZ5l",
        "outputId": "232cd8e6-0676-4238-e08d-b05714131b3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rank(A) = 4\n",
            "Q:\n",
            " [[ 0.68199924 -0.14289077  0.13514966 -0.70441027]\n",
            " [ 0.33606173  0.01977186  0.81180873  0.47711442]\n",
            " [ 0.6409567  -0.02104702 -0.56799993  0.51585619]\n",
            " [ 0.10542328  0.9893171  -0.00878792 -0.10030144]]\n",
            "R:\n",
            " [[1.35384788 0.89162028 1.26204609 0.79034448]\n",
            " [0.         0.73558047 0.74951318 0.03668232]\n",
            " [0.         0.         0.67203033 0.72197242]\n",
            " [0.         0.         0.         0.29381458]]\n"
          ]
        }
      ],
      "source": [
        "# arbitrary matrix A\n",
        "'''\n",
        "A = np.array([[1,0,0,0],\n",
        "              [1,0,0,5],\n",
        "              [0,3,8,3],\n",
        "              [3,3,3,3,]])\n",
        "'''\n",
        "A = np.random.rand(4,4)\n",
        "# check for rank\n",
        "print(\"Rank(A) =\", np.linalg.matrix_rank(A))\n",
        "\n",
        "Q, R = QR_factorization(A)\n",
        "print(\"Q:\\n\",Q)\n",
        "print(\"R:\\n\",R)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mi0iGCVerZ5l"
      },
      "source": [
        "Calulate Frobenius norms $||Q^TQ-I||_F, ||QR-A||_F$:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aexDj9YNrZ5l",
        "outputId": "97fba14d-c4f1-48a4-af55-577cf0a60b17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm(A-QR): 2.0816681711721685e-16\n",
            "Norm(Q^T*Q-I): 1.4464646466968441e-15\n"
          ]
        }
      ],
      "source": [
        "print(\"Norm(A-QR):\", np.linalg.norm(A-np.matmul(Q,R), 'fro'))\n",
        "print(\"Norm(Q^T*Q-I):\", np.linalg.norm(np.matmul(Q.transpose(),Q)-np.eye(Q.shape[0]), 'fro'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7mjSFCPrZ5l"
      },
      "source": [
        "... one can see that both norms are 0 (considering machine precision)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urB3aECOrZ5l"
      },
      "source": [
        "### **3. Function: direct solver Ax=b**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJ1WCI8GrZ5m",
        "outputId": "517db233-c840-4047-c6b7-7ef131ef113f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x with solver:\t [ 1.  1. -0.]\n",
            "x custom :\t [ 9.99999998e-01  1.00000004e+00 -1.52235605e-08]\n"
          ]
        }
      ],
      "source": [
        "# input\n",
        "A = np.array([[1,0,0],\n",
        "              [1,1,0],\n",
        "              [0,3,8]])\n",
        "b = np.array([1,2,3])\n",
        "\n",
        "# excute function\n",
        "x = richardson_iteration(A, b, alpha=0.01, tol=10**-8)\n",
        "\n",
        "# calculate exact solution\n",
        "y = np.linalg.solve(A,b)\n",
        "\n",
        "print(\"x with solver:\\t\", y)\n",
        "print(\"x custom :\\t\", x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N33YqOftrZ5m"
      },
      "source": [
        "Calculate residual $||Ax-b||$ and $||x-y||$ where y is the exact solution:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6VguIz3rZ5m",
        "outputId": "fc255c58-0cfc-4d13-eedc-415a59e8defd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Norm(Ax-b) = 3.691064427594355e-08\n",
            "Norm(x-y) = 3.8935891043404126e-08\n"
          ]
        }
      ],
      "source": [
        "print(\"Norm(Ax-b) =\", np.linalg.norm(np.matmul(A,x)-b))\n",
        "print(\"Norm(x-y) =\", np.linalg.norm(x-y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBolikMgrZ5m"
      },
      "source": [
        "... one can see that both norms are in the value range of the chosen tolerance. Decreasing the tolerance will increase the precision but also increase computational cost.\n",
        "\n",
        "Let's visualize the convergence:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "iKvB0cPVrZ5n",
        "outputId": "7580a108-3f4c-492d-f66b-56841f21b3c7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'error_norm')"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "def richardson_iteration_error(A, b, alpha, tol):\n",
        "    y = np.linalg.solve(A,b)\n",
        "    n = len(b)\n",
        "    x = np.zeros(n)\n",
        "    r = b\n",
        "    b_norm = np.linalg.norm(b)\n",
        "    err = []\n",
        "    while np.linalg.norm(r)/b_norm > tol:\n",
        "        r = np.matmul(A,x)\n",
        "        r = b - r\n",
        "        x = x + alpha * r\n",
        "        err.append(np.linalg.norm(x-y))\n",
        "    return err\n",
        "\n",
        "error = richardson_iteration_error(A, b, alpha=0.01, tol=0.001)\n",
        "\n",
        "plt.plot(range(len(error)), error)\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"error_norm\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGRIbBa4rZ5n"
      },
      "source": [
        "... one can see that for even a high tolerance a lot of iterations have to be done."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4GLBv0zWr7m"
      },
      "source": [
        "# **Discussion**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6bcsDSoRXHZe"
      },
      "source": [
        "Condluding one can say that each of the algorithms fulfills its purpose. As stated in the introduction the efficiency (time and memory) is usually a critical factor which is probably the biggest flaw concerning function 2 and 3. But the used functions are fairly simple and still useful for smaller caclulations that are not critical about efficiency."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}