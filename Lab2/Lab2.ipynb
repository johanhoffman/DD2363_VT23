{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RgtXlfYO_i7"
      },
      "source": [
        "# **Lab 2: Iterative methods**\n",
        "**Jesper Lidaum**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9x_J5FVuPzbm"
      },
      "source": [
        "# **Abstract**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UFTSzW7P8kL"
      },
      "source": [
        "In this report we implement 3 methods for solving equations and systems of equations. The first two are for solving systems of linear equations represented on matrix vector form. The last is for solving a real scalar equation. We implement Jordan itteration, Gauss-Seidel itteration and Newton's method.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OkT8J7uOWpT3"
      },
      "source": [
        "#**About the code**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmB2noTr1Oyo"
      },
      "source": [
        "A short statement on who is the author of the file, and if the code is distributed under a certain license. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pdll1Xc9WP0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "aee1096c-8ca0-40b5-c6c5-45d03bb7930a"
      },
      "source": [
        "\"\"\"This program is a template for lab reports in the course\"\"\"\n",
        "\"\"\"DD2363 Methods in Scientific Computing, \"\"\"\n",
        "\"\"\"KTH Royal Institute of Technology, Stockholm, Sweden.\"\"\"\n",
        "\n",
        "# Copyright (C) 2023 Jesper Lidbaum (jlidbaum@kth.se)\n",
        "\n",
        "# This file is part of the course DD2365 Advanced Computation in Fluid Mechanics\n",
        "# KTH Royal Institute of Technology, Stockholm, Sweden\n",
        "#\n",
        "# This is free software: you can redistribute it and/or modify\n",
        "# it under the terms of the GNU Lesser General Public License as published by\n",
        "# the Free Software Foundation, either version 3 of the License, or\n",
        "# (at your option) any later version.\n",
        "\n",
        "# This template is maintained by Johan Hoffman\n",
        "# Please report problems to jhoffman@kth.se"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'KTH Royal Institute of Technology, Stockholm, Sweden.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28xLGz8JX3Hh"
      },
      "source": [
        "# **Set up environment**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2PYNusD08Wa"
      },
      "source": [
        "To have access to the neccessary modules you have to run this cell. If you need additional modules, this is where you add them. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xw7VlErAX7NS"
      },
      "source": [
        "# Load neccessary modules.\n",
        "from google.colab import files\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "#try:\n",
        "#    from dolfin import *; from mshr import *\n",
        "#except ImportError as e:\n",
        "#    !apt-get install -y -qq software-properties-common \n",
        "#    !add-apt-repository -y ppa:fenics-packages/fenics\n",
        "#    !apt-get update -qq\n",
        "#    !apt install -y --no-install-recommends fenics\n",
        "#    from dolfin import *; from mshr import *\n",
        "    \n",
        "#import dolfin.common.plotting as fenicsplot\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib import tri\n",
        "from matplotlib import axes\n",
        "from mpl_toolkits.mplot3d import Axes3D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnO3lhAigLev"
      },
      "source": [
        "# **Introduction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5zMzgPlRAF6"
      },
      "source": [
        "This report implements 2 itterations described with mathematical formulas in the [course book](https://my.siam.org/Store/Product/viewproduct/?ProductId=39300058). And also the well known Newton's method which is described with psuedo code in the same book. \n",
        "\n",
        "## Jacobi iteration\n",
        "The Jacobi iteration implemented in this report is based on chapter 7.7 in the course book. Jacobi iteration is related to Richardson iteration where we create the iterations matrix from two matricies $A=A_1+A_2$ where $A_1$ are the diagonal elements in $A$ and $A_2$ are the rest. From the course book we get the converge criterion $‖I−A_1^{-1}A‖<1$ for the iteration. And the iteration implemented in this lab can be found in example 7.8.\n",
        "\n",
        "## Gauss-Seidel iteration\n",
        "The Gauss-Seidel iteration is also related to the Richardson iteration. The iteration matrix is constructed by the upper triangular elements of $A$ and the rest. From example 7.9 in the course book we get the converge criterion $‖I−L^{−1}A‖<1$ where $L$ is the lower triangular elements of $A$. We also get the iteration that is implemented in this report from the same example.\n",
        "\n",
        "## Newton's method\n",
        "Newton's method is a method for solving nonlinear equations $f(x) = 0$. It takes the form $x^{(k+1)} = x^{(k)} - f(x^{(k)}) / f'(x^{(k)})$. The code in this report is based on algorithm 8.2 from the course book. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOQvukXZq5U5"
      },
      "source": [
        "# **Method**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zF4iBj5VURZx"
      },
      "source": [
        "In this part code for each of the algortihms are presented. The code is based on formulas and psuedo code from the course book.\n",
        "\n",
        "## Jacobi iteration\n",
        "The code is based on the iteration from example 7.8 in the course book. The stopping criterion is from chapter 7, page 145 where it is recomended to use that stopping criterion if we initialize with a zero vector. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def jacobi_iteration(A, b):\n",
        "\n",
        "    TOL = 1e-6\n",
        "    n = np.shape(b)[0]\n",
        "    x = np.zeros(n)\n",
        "    x_new = np.zeros(n)\n",
        "\n",
        "    r = b - np.dot(A, x)\n",
        "\n",
        "    while np.linalg.norm(r)/ np.linalg.norm(b) > TOL:    # stopping criterion based on Chapter 7, page 145      \n",
        "        for i in range(n):\n",
        "            s = 0\n",
        "            for j in range(n):\n",
        "                if j != i:\n",
        "                    s += A[i,j] * x[j]\n",
        "            x_new[i] = (b[i] - s) / A[i,i]\n",
        "        x = x_new\n",
        "        r = b - np.dot(A, x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "gjoKdjOKeo0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Gauss-Seidel iteration\n",
        "## Jacobi iteration\n",
        "The code is based on the iteration from example 7.9 in the course book. As with the last iteration we use the stopping criterion from page 145. "
      ],
      "metadata": {
        "id": "4Jsa-ohMexbE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gauss_seidel_iteration(A, b):\n",
        "    TOL = 1e-6\n",
        "    n = np.shape(b)[0]\n",
        "    x = np.zeros(n)\n",
        "    x_new = np.zeros(n)\n",
        "\n",
        "    r = b - np.dot(A, x)\n",
        "    while np.linalg.norm(r) / np.linalg.norm(b) > TOL:  # stopping criterion based on Chapter 7, page 145    \n",
        "        for i in range(n):\n",
        "            s1 = 0\n",
        "            s2 = 0\n",
        "            for j in range(n):\n",
        "                if j < i:\n",
        "                    s1 += A[i,j] * x_new[j]\n",
        "                if j > i:\n",
        "                    s2 += A[i,j] * x[j]\n",
        "            x_new[i] = (b[i] - s1 - s2) / A[i,i]\n",
        "        x = x_new\n",
        "        r = b - np.dot(A, x)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "l6HmKhBme11S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Newton's method\n",
        "This code is based on algortihm 8.2 in the course book. One possible problem with this algortihm is that is there are two solutions for example for a quadratic equation, it will only converge to one of the solutions, more if we start at an extreme point for $f$ we will divide by zero so the iteration wont terminate. From lecture 4 we have that the method will have quadratic convergence to the solution assuming that we start close to the solution and that $f$ is at least $C²$ continous."
      ],
      "metadata": {
        "id": "mYSVK2NYe4Mh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def newtons_method(f, df):\n",
        "    x = 0.01\n",
        "    TOL = 1e-6\n",
        "    while np.abs(f(x)) > TOL:\n",
        "        x = x - f(x) / df(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "uStujEMZe6AE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsQLT38gVbn_"
      },
      "source": [
        "# **Results**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLwlnOzuV-Cd"
      },
      "source": [
        "In this part we present tests on the code and their results.\n",
        "\n",
        "## Jacobi iteration\n",
        "We test the Jacobi iteration on a small system of equations. The residual norm and the distance from the real result is printed."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_jacobi_iteration():\n",
        "    A = np.array([[2, -1], [-1, 2]])\n",
        "    b = np.array([1, 1])\n",
        "    real_root = np.array([1, 1])\n",
        "    x = jacobi_iteration(A, b)\n",
        "    return np.linalg.norm(A.dot(x) - b), np.linalg.norm(x - real_root)\n",
        "\n",
        "print(test_jacobi_iteration())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fazb2fMci3PR",
        "outputId": "50cbade5-e332-41b1-af08-3a8f81e7f86c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3.5762786865234375e-07, 2.6656007498500226e-07)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gauss-Seidel iteration\n",
        "We test the Gauss-Seidel iteration on a small system of equations. The residual norm and the distance from the real result is printed."
      ],
      "metadata": {
        "id": "EmbNiCL-i3hE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_gauss_seidel_iteration():\n",
        "    A = np.array([[2, -1], [-1, 2]])\n",
        "    b = np.array([1, 1])\n",
        "    real_root = np.array([1, 1])\n",
        "    x = gauss_seidel_iteration(A, b)\n",
        "    return np.linalg.norm(A.dot(x) - b), np.linalg.norm(x - real_root)\n",
        "\n",
        "print(test_gauss_seidel_iteration())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-8Acdrli5Lt",
        "outputId": "e926b2ef-e1e2-4119-81be-1aeef7d2b069"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7.152557373046875e-07, 5.331201499700045e-07)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Newton's method\n",
        "We test newtond method on $x^2 -2 = 0$ with $f(x) = x^2 - 2$ and $f'(x) = 2x$. $|f(x)|$ where $x$ is the result and the distance from the real result is printed."
      ],
      "metadata": {
        "id": "63HR8sVpi5zM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_newtons_method():\n",
        "    f = lambda x: x**2 - 2\n",
        "    df = lambda x: 2*x\n",
        "    real_root = np.sqrt(2)\n",
        "    x = newtons_method(f, df)\n",
        "    return np.abs(f(x)), np.abs(x - real_root)\n",
        "\n",
        "print(test_newtons_method())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QzUDxgdHjVDw",
        "outputId": "fed31147-b0f0-4a48-86df-87ae9ed7dbdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2.1103119252074976e-12, 7.460698725481052e-13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Discussion**\n",
        "The code seem to work on the tests. In real code in an application I would probably also include checks to see that the convergence criterion is met for the first two iterations. Newtonds method has a pretty obvoius weakness which is that its converge depends on the function and starting point. So some care has to be taken into account when choosing starting point.\n"
      ],
      "metadata": {
        "id": "81gUderWj0-k"
      }
    }
  ]
}